{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from accelerate import Accelerator, DistributedDataParallelKwargs\n",
    "\n",
    "import transformers\n",
    "from transformers import BertConfig, BertModel, BertTokenizer\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "\n",
    "#########################################\n",
    "# Helper functions\n",
    "#########################################\n",
    "def time_features(dates, freq='h'):\n",
    "    \"\"\"\n",
    "    Generate time features from dates, returning an array of shape\n",
    "    (num_features, num_dates) containing month, day, weekday, and hour.\n",
    "    \"\"\"\n",
    "    dates = pd.to_datetime(dates)\n",
    "    month = dates.month.values.astype(float)\n",
    "    day = dates.day.values.astype(float)\n",
    "    weekday = dates.weekday.values.astype(float)\n",
    "    hour = dates.hour.values.astype(float)\n",
    "    return np.stack([month, day, weekday, hour], axis=0)\n",
    "\n",
    "\n",
    "#########################################\n",
    "# Dataset definition (loads both CSV and video features .pt)\n",
    "#########################################\n",
    "class Dataset_Custom(Dataset):\n",
    "    def __init__(self, root_path, flag='train', size=None,\n",
    "                 data_path='PKU_Skeleton_Renew_preprocessed_0002-L.csv',\n",
    "                 scale=True, timeenc=0, freq='h', percent=100, seasonal_patterns=None):\n",
    "        # If size is not specified, default to set sequence, label, and prediction lengths\n",
    "        if size is None:\n",
    "            self.seq_len = 24 * 4 * 4\n",
    "            self.label_len = 24 * 4\n",
    "            self.pred_len = 24 * 4\n",
    "        else:\n",
    "            self.seq_len, self.label_len, self.pred_len = size\n",
    "\n",
    "        assert flag in ['train', 'test', 'val']\n",
    "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
    "        self.set_type = type_map[flag]\n",
    "        self.scale = scale\n",
    "        self.timeenc = timeenc\n",
    "        self.freq = freq\n",
    "        self.percent = percent\n",
    "        self.root_path = root_path\n",
    "        self.data_path = data_path\n",
    "        self.__read_data__()\n",
    "\n",
    "        # Iterate over each CSV feature column (enc_in) to form samples\n",
    "        self.enc_in = self.data_x.shape[-1]  # CSV data dimension (e.g., 75)\n",
    "        self.tot_len = len(self.data_x) - self.seq_len - self.pred_len + 1\n",
    "\n",
    "    def __read_data__(self):\n",
    "        # Read CSV file and parse dates\n",
    "        df_raw = pd.read_csv(os.path.join(self.root_path, self.data_path))\n",
    "        df_raw['date'] = pd.to_datetime(df_raw['date'])\n",
    "        # CSV data: all columns except date\n",
    "        df_csv = df_raw.drop('date', axis=1)\n",
    "\n",
    "        # Load video features .pt file (must have same number of rows as CSV)\n",
    "        pt_path = os.path.join(self.root_path, \"video-2_features.pt\")\n",
    "        video_features = torch.load(pt_path, map_location=torch.device('cpu'))\n",
    "        assert video_features.shape[0] == len(df_raw), \"Number of rows in video features does not match CSV dates!\"\n",
    "        # Linear mapping: map each 2048-dim video feature row to 200-dim (learnable, not frozen)\n",
    "        linear_mapping = nn.Linear(2048, 200)\n",
    "        mapped_features = linear_mapping(video_features)  # [T, 200]\n",
    "        mapped_features = mapped_features.detach().numpy()\n",
    "\n",
    "        # Standardize CSV data (using training statistics) and video features separately\n",
    "        self.scaler_csv = StandardScaler()\n",
    "        self.scaler_pt = StandardScaler()\n",
    "        num_train = int(len(df_raw) * 0.7)\n",
    "        num_test = int(len(df_raw) * 0.2)\n",
    "        num_vali = len(df_raw) - num_train - num_test\n",
    "        border1s = [0, num_train - self.seq_len, len(df_raw) - num_test - self.seq_len]\n",
    "        border2s = [num_train, num_train + num_vali, len(df_raw)]\n",
    "        border1 = border1s[self.set_type]\n",
    "        border2 = border2s[self.set_type]\n",
    "        if self.set_type == 0:\n",
    "            border2 = (border2 - self.seq_len) * self.percent // 100 + self.seq_len\n",
    "\n",
    "        # CSV data standardization\n",
    "        train_csv = df_csv.iloc[border1s[0]:border2s[0]].values\n",
    "        self.scaler_csv.fit(train_csv)\n",
    "        csv_data = self.scaler_csv.transform(df_csv.values)\n",
    "\n",
    "        # Video features standardization\n",
    "        train_pt = mapped_features[border1s[0]:border2s[0]]\n",
    "        self.scaler_pt.fit(train_pt)\n",
    "        pt_data = self.scaler_pt.transform(mapped_features)\n",
    "\n",
    "        # Generate timestamp features\n",
    "        df_stamp = df_raw[['date']].iloc[border1:border2]\n",
    "        if self.timeenc == 0:\n",
    "            df_stamp['month'] = df_stamp['date'].apply(lambda row: row.month)\n",
    "            df_stamp['day'] = df_stamp['date'].apply(lambda row: row.day)\n",
    "            df_stamp['weekday'] = df_stamp['date'].apply(lambda row: row.weekday())\n",
    "            df_stamp['hour'] = df_stamp['date'].apply(lambda row: row.hour)\n",
    "            data_stamp = df_stamp.drop(['date'], axis=1).values\n",
    "        elif self.timeenc == 1:\n",
    "            data_stamp = time_features(df_stamp['date'].values, freq=self.freq)\n",
    "            data_stamp = data_stamp.transpose(1, 0)\n",
    "\n",
    "        # Only use CSV part as labels (forecast output only uses CSV encoding)\n",
    "        self.data_x = csv_data[border1:border2]  # CSV inputs, shape [T, num_csv_features]\n",
    "        self.data_y = csv_data[border1:border2]\n",
    "        # Keep all dimensions for video features\n",
    "        self.data_pt = pt_data[border1:border2]  # video inputs, shape [T, 200]\n",
    "        self.data_stamp = data_stamp\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Use CSV feature count to index each variable\n",
    "        tot_len = self.tot_len\n",
    "        feat_id = index // tot_len  # CSV feature index (0 to enc_in-1)\n",
    "        s_begin = index % tot_len\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end - self.label_len\n",
    "        r_end = r_begin + self.label_len + self.pred_len\n",
    "        # CSV part: take one variable column\n",
    "        seq_x_csv = self.data_x[s_begin:s_end, feat_id:feat_id+1]\n",
    "        seq_y = self.data_y[r_begin:r_end, feat_id:feat_id+1]\n",
    "        # Video features part: also take corresponding single variable\n",
    "        seq_x_pt = self.data_pt[s_begin:s_end, feat_id:feat_id+1]\n",
    "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
    "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
    "        return seq_x_csv, seq_x_pt, seq_y, seq_x_mark, seq_y_mark\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.data_x) - self.seq_len - self.pred_len + 1) * self.data_x.shape[-1]\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return self.scaler_csv.inverse_transform(data)\n",
    "\n",
    "class Dataset_ETT_hour(Dataset_Custom):\n",
    "    pass\n",
    "\n",
    "def data_provider(args, flag):\n",
    "    Data = Dataset_ETT_hour\n",
    "    timeenc = 0 if args.embed != 'timeF' else 1\n",
    "    percent = args.percent\n",
    "    if flag == 'test':\n",
    "        shuffle_flag = False\n",
    "        drop_last = True\n",
    "        batch_size = args.batch_size\n",
    "        freq = args.freq\n",
    "    else:\n",
    "        shuffle_flag = True\n",
    "        drop_last = True\n",
    "        batch_size = args.batch_size\n",
    "        freq = args.freq\n",
    "    data_set = Data(\n",
    "        root_path=args.root_path,\n",
    "        data_path=args.data_path,\n",
    "        flag=flag,\n",
    "        size=[args.seq_len, args.label_len, args.pred_len],\n",
    "        scale=args.scale,\n",
    "        timeenc=timeenc,\n",
    "        freq=freq,\n",
    "        percent=percent,\n",
    "        seasonal_patterns=args.seasonal_patterns\n",
    "    )\n",
    "    data_loader = DataLoader(\n",
    "        data_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle_flag,\n",
    "        num_workers=args.num_workers,\n",
    "        drop_last=drop_last)\n",
    "    return data_set, data_loader\n",
    "\n",
    "\n",
    "#########################################\n",
    "# Model components\n",
    "#########################################\n",
    "# FlattenHead: flatten and linearly map to the prediction window\n",
    "class FlattenHead(nn.Module):\n",
    "    def __init__(self, n_vars, nf, target_window, head_dropout=0):\n",
    "        super().__init__()\n",
    "        self.n_vars = n_vars\n",
    "        self.flatten = nn.Flatten(start_dim=-2)\n",
    "        self.linear = nn.Linear(nf, target_window)\n",
    "        self.dropout = nn.Dropout(head_dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "# PositionalEmbedding: positional encoding\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float() *\n",
    "                    -(math.log(10000.0) / d_model)).exp()\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "# TokenEmbedding: 1D convolutional embedding\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        padding = 1 if torch.__version__ >= '1.5.0' else 2\n",
    "        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model,\n",
    "                                   kernel_size=3, padding=padding,\n",
    "                                   padding_mode='circular', bias=False)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in',\n",
    "                                        nonlinearity='leaky_relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "# FixedEmbedding: fixed sinusoidal embedding\n",
    "class FixedEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(FixedEmbedding, self).__init__()\n",
    "        w = torch.zeros(c_in, d_model).float()\n",
    "        w.require_grad = False\n",
    "        position = torch.arange(0, c_in).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float() *\n",
    "                    -(math.log(10000.0) / d_model)).exp()\n",
    "        w[:, 0::2] = torch.sin(position * div_term)\n",
    "        w[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.emb = nn.Embedding(c_in, d_model)\n",
    "        self.emb.weight = nn.Parameter(w, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.emb(x).detach()\n",
    "\n",
    "# TemporalEmbedding: time feature embedding\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='fixed', freq='h'):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "        minute_size = 4\n",
    "        hour_size = 24\n",
    "        weekday_size = 7\n",
    "        day_size = 32\n",
    "        month_size = 13\n",
    "        Embed = FixedEmbedding if embed_type == 'fixed' else nn.Embedding\n",
    "        if freq == 't':\n",
    "            self.minute_embed = Embed(minute_size, d_model)\n",
    "        self.hour_embed = Embed(hour_size, d_model)\n",
    "        self.weekday_embed = Embed(weekday_size, d_model)\n",
    "        self.day_embed = Embed(day_size, d_model)\n",
    "        self.month_embed = Embed(month_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.long()\n",
    "        minute_x = self.minute_embed(x[:, :, 4]) if hasattr(self, 'minute_embed') else 0.\n",
    "        hour_x = self.hour_embed(x[:, :, 3])\n",
    "        weekday_x = self.weekday_embed(x[:, :, 2])\n",
    "        day_x = self.day_embed(x[:, :, 1])\n",
    "        month_x = self.month_embed(x[:, :, 0])\n",
    "        return hour_x + weekday_x + day_x + month_x + minute_x\n",
    "\n",
    "# TimeFeatureEmbedding: embedding for timeF type features\n",
    "class TimeFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, embed_type='timeF', freq='h'):\n",
    "        super(TimeFeatureEmbedding, self).__init__()\n",
    "        freq_map = {'h': 4, 't': 5, 's': 6, 'm': 1, 'a': 1, 'w': 2, 'd': 3, 'b': 3}\n",
    "        d_inp = freq_map[freq]\n",
    "        self.embed = nn.Linear(d_inp, d_model, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "# DataEmbedding: combine value, positional, and time embeddings\n",
    "class DataEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n",
    "        super(DataEmbedding, self).__init__()\n",
    "        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n",
    "        self.position_embedding = PositionalEmbedding(d_model=d_model)\n",
    "        self.temporal_embedding = (TemporalEmbedding(d_model=d_model, embed_type=embed_type, freq=freq)\n",
    "                                   if embed_type != 'timeF'\n",
    "                                   else TimeFeatureEmbedding(d_model=d_model, embed_type=embed_type, freq=freq))\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, x_mark):\n",
    "        if x_mark is None:\n",
    "            x = self.value_embedding(x) + self.position_embedding(x).to(x.device)\n",
    "        else:\n",
    "            x = (self.value_embedding(x) +\n",
    "                 self.temporal_embedding(x_mark) +\n",
    "                 self.position_embedding(x))\n",
    "        return self.dropout(x)\n",
    "\n",
    "# ReplicationPad1d: replicate padding\n",
    "class ReplicationPad1d(nn.Module):\n",
    "    def __init__(self, padding) -> None:\n",
    "        super(ReplicationPad1d, self).__init__()\n",
    "        self.padding = padding\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        replicate_padding = input[:, :, -1].unsqueeze(-1).repeat(1, 1, self.padding[-1])\n",
    "        output = torch.cat([input, replicate_padding], dim=-1)\n",
    "        return output\n",
    "\n",
    "# PatchEmbedding: divide input into patches and embed\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, patch_len, stride, dropout):\n",
    "        super(PatchEmbedding, self).__init__()\n",
    "        self.patch_len = patch_len\n",
    "        self.stride = stride\n",
    "        self.padding_patch_layer = ReplicationPad1d((0, stride))\n",
    "        # TokenEmbedding input channels equal patch length\n",
    "        self.value_embedding = TokenEmbedding(patch_len, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, C, T] where C is channel count (e.g., CSV: 1, video: 200)\n",
    "        n_vars = x.shape[1]\n",
    "        x = self.padding_patch_layer(x)\n",
    "        x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n",
    "        # reshape [B, C, L, patch_len] to [B*C, L, patch_len]\n",
    "        x = torch.reshape(x, (x.shape[0] * x.shape[1], x.shape[2], x.shape[3]))\n",
    "        x = self.value_embedding(x)\n",
    "        return self.dropout(x), n_vars\n",
    "\n",
    "# Normalize: normalization and denormalization module\n",
    "class Normalize(nn.Module):\n",
    "    def __init__(self, num_features: int, eps=1e-5, affine=False,\n",
    "                 subtract_last=False, non_norm=False):\n",
    "        super(Normalize, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "        self.subtract_last = subtract_last\n",
    "        self.non_norm = non_norm\n",
    "        if self.affine:\n",
    "            self._init_params()\n",
    "\n",
    "    def forward(self, x, mode: str):\n",
    "        if mode == 'norm':\n",
    "            self._get_statistics(x)\n",
    "            x = self._normalize(x)\n",
    "        elif mode == 'denorm':\n",
    "            x = self._denormalize(x)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return x\n",
    "\n",
    "    def _init_params(self):\n",
    "        self.affine_weight = nn.Parameter(torch.ones(self.num_features))\n",
    "        self.affine_bias = nn.Parameter(torch.zeros(self.num_features))\n",
    "\n",
    "    def _get_statistics(self, x):\n",
    "        dim2reduce = tuple(range(1, x.ndim - 1))\n",
    "        if self.subtract_last:\n",
    "            self.last = x[:, -1, :].unsqueeze(1)\n",
    "        else:\n",
    "            self.mean = torch.mean(x, dim=dim2reduce, keepdim=True).detach()\n",
    "        self.stdev = torch.sqrt(torch.var(x, dim=dim2reduce,\n",
    "                           keepdim=True, unbiased=False) + self.eps).detach() \n",
    "\n",
    "    def _normalize(self, x):\n",
    "        if self.non_norm:\n",
    "            return x\n",
    "        if self.subtract_last:\n",
    "            x = x - self.last\n",
    "        else:\n",
    "            x = x - self.mean\n",
    "        x = x / self.stdev\n",
    "        if self.affine:\n",
    "            x = x * self.affine_weight + self.affine_bias\n",
    "        return x\n",
    "\n",
    "    def _denormalize(self, x):\n",
    "        if self.non_norm:\n",
    "            return x\n",
    "        if self.affine:\n",
    "            x = (x - self.affine_bias) / (self.affine_weight + self.eps * self.eps)\n",
    "        x = x * self.stdev\n",
    "        if self.subtract_last:\n",
    "            x = x + self.last\n",
    "        else:\n",
    "            x = x + self.mean\n",
    "        return x\n",
    "\n",
    "# ReprogrammingLayer: aligns patch embeddings with pretrained model embeddings\n",
    "class ReprogrammingLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_keys=None, d_llm=None,\n",
    "                 attention_dropout=0.1):\n",
    "        super(ReprogrammingLayer, self).__init__()\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_llm, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_llm, d_keys * n_heads)\n",
    "        self.out_projection = nn.Linear(d_keys * n_heads, d_llm)\n",
    "        self.n_heads = n_heads\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "\n",
    "    def forward(self, target_embedding, source_embedding, value_embedding):\n",
    "        B, L, _ = target_embedding.shape\n",
    "        S, _ = source_embedding.shape\n",
    "        H = self.n_heads\n",
    "        target_embedding = self.query_projection(target_embedding).view(B, L, H, -1)\n",
    "        source_embedding = self.key_projection(source_embedding).view(S, H, -1)\n",
    "        value_embedding = self.value_projection(value_embedding).view(S, H, -1)\n",
    "        out = self.reprogramming(target_embedding, source_embedding, value_embedding)\n",
    "        out = out.reshape(B, L, -1)\n",
    "        return self.out_projection(out)\n",
    "\n",
    "    def reprogramming(self, target_embedding, source_embedding, value_embedding):\n",
    "        B, L, H, E = target_embedding.shape\n",
    "        scale = 1. / math.sqrt(E)\n",
    "        scores = torch.einsum(\"blhe,she->bhls\", target_embedding, source_embedding)\n",
    "        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n",
    "        reprogramming_embedding = torch.einsum(\"bhls,she->blhe\", A, value_embedding)\n",
    "        return reprogramming_embedding\n",
    "\n",
    "\n",
    "#########################################\n",
    "# TimeLLM model using fixed BERT\n",
    "#########################################\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, configs, patch_len=16, stride=8):\n",
    "        super(Model, self).__init__()\n",
    "        self.task_name = configs.task_name\n",
    "        self.pred_len = configs.pred_len\n",
    "        self.seq_len = configs.seq_len\n",
    "        self.d_ff = configs.d_ff\n",
    "        self.top_k = 5\n",
    "        self.d_llm = configs.llm_dim  # match BERT hidden size, default 768\n",
    "        self.patch_len = configs.patch_len\n",
    "        self.stride = configs.stride\n",
    "\n",
    "        # Force use of BERT\n",
    "        configs.llm_model = 'BERT'\n",
    "        self.bert_config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "        self.bert_config.num_hidden_layers = configs.llm_layers  \n",
    "        self.bert_config.output_attentions = True\n",
    "        self.bert_config.output_hidden_states = True\n",
    "\n",
    "        try:\n",
    "            self.llm_model = BertModel.from_pretrained(\n",
    "                \"bert-base-uncased\", config=self.bert_config)\n",
    "        except EnvironmentError:\n",
    "            print(\"Local model files not found, attempting download...\")\n",
    "            self.llm_model = BertModel.from_pretrained(\n",
    "                \"bert-base-uncased\", config=self.bert_config)\n",
    "\n",
    "        try:\n",
    "            self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        except EnvironmentError:\n",
    "            print(\"Local tokenizer not found, attempting download...\")\n",
    "            self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "        if self.tokenizer.eos_token:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        else:\n",
    "            pad_token = '[PAD]'\n",
    "            self.tokenizer.add_special_tokens({'pad_token': pad_token})\n",
    "            self.tokenizer.pad_token = pad_token\n",
    "\n",
    "        # Freeze BERT parameters\n",
    "        for param in self.llm_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        if configs.prompt_domain:\n",
    "            self.description = configs.content\n",
    "        else:\n",
    "            self.description = (\n",
    "                'The 3D spatial positions of the 25 keypoints of the human body '\n",
    "                'serve as essential benchmarks for human pose trajectory prediction.')\n",
    "\n",
    "        self.dropout = nn.Dropout(configs.dropout)\n",
    "        # Create PatchEmbedding for CSV and video features\n",
    "        self.csv_patch_embedding = PatchEmbedding(\n",
    "            configs.d_model, self.patch_len, self.stride, configs.dropout)\n",
    "        self.pt_patch_embedding = PatchEmbedding(\n",
    "            configs.d_model, self.patch_len, self.stride, configs.dropout)\n",
    "        self.word_embeddings = self.llm_model.get_input_embeddings().weight\n",
    "        self.vocab_size = self.word_embeddings.shape[0]\n",
    "        self.num_tokens = 1000\n",
    "        self.mapping_layer = nn.Linear(self.vocab_size, self.num_tokens)\n",
    "        self.reprogramming_layer = ReprogrammingLayer(\n",
    "            configs.d_model, configs.n_heads, self.d_ff, self.d_llm)\n",
    "        # Compute number of CSV patches\n",
    "        self.patch_nums = int((configs.seq_len - self.patch_len) / self.stride + 2)\n",
    "        self.head_nf = self.d_ff * self.patch_nums\n",
    "        if self.task_name in ['long_term_forecast', 'short_term_forecast']:\n",
    "            self.output_projection = FlattenHead(\n",
    "                configs.enc_in, self.head_nf, self.pred_len,\n",
    "                head_dropout=configs.dropout)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.normalize_layers = Normalize(configs.enc_in, affine=False)\n",
    "\n",
    "    def forward(self, x_csv, x_pt, x_mark_enc, x_dec, x_mark_dec, mask=None):\n",
    "        if self.task_name in ['long_term_forecast', 'short_term_forecast']:\n",
    "            dec_out = self.forecast(x_csv, x_pt, x_mark_enc, x_dec, x_mark_dec)\n",
    "            return dec_out[:, -self.pred_len:, :]\n",
    "        return None\n",
    "\n",
    "    def forecast(self, x_csv, x_pt, x_mark_enc, x_dec, x_mark_dec):\n",
    "        # x_csv: [B, T, csv_dim]; x_pt: [B, T, pt_dim]\n",
    "        # Normalize both CSV and video inputs\n",
    "        x_csv = self.normalize_layers(x_csv, 'norm')\n",
    "        x_pt = self.normalize_layers(x_pt, 'norm')\n",
    "        B, T, _ = x_csv.size()\n",
    "\n",
    "        # Compute CSV stats for prompt\n",
    "        csv_for_stats = x_csv.permute(0, 2, 1).contiguous().reshape(\n",
    "            B * x_csv.shape[-1], T, 1)\n",
    "        min_values = torch.min(csv_for_stats, dim=1)[0]\n",
    "        max_values = torch.max(csv_for_stats, dim=1)[0]\n",
    "        medians = torch.median(csv_for_stats, dim=1).values\n",
    "        lags = self.calcute_lags(csv_for_stats)\n",
    "        trends = x_csv.permute(0, 2, 1).contiguous().reshape(\n",
    "            B * x_csv.shape[-1], T, 1).diff(dim=1).sum(dim=1)\n",
    "        prompt = []\n",
    "        for b in range(csv_for_stats.shape[0]):\n",
    "            min_str = str(min_values[b].tolist()[0])\n",
    "            max_str = str(max_values[b].tolist()[0])\n",
    "            median_str = str(medians[b].tolist()[0])\n",
    "            lags_str = str(lags[b].tolist())\n",
    "            prompt_.join = (\n",
    "                f\"<|start_prompt|>Dataset description: {self.description}. \"\n",
    "                f\"Task: Forecast the next {self.pred_len} steps given the previous \"\n",
    "                f\"{self.seq_len} steps; Input statistics: min value {min_str}, \"\n",
    "                f\"max value {max_str}, median value {median_str}, \"\n",
    "                f\"trend is {'upward' if trends[b] > 0 else 'downward'}, \"\n",
    "                f\"top 5 lags: {lags_str}<|<end_prompt>|>\"\n",
    "            )\n",
    "            prompt.append(prompt_)\n",
    "        # Tokenize prompt\n",
    "        prompt_tokens = self.tokenizer(\n",
    "            prompt, return_tensors=\"pt\", padding=True,\n",
    "            truncation=True, max_length=2048).input_ids\n",
    "        prompt_embeddings = self.llm_model.get_input_embeddings()(\n",
    "            prompt_tokens.to(x_csv.device))\n",
    "\n",
    "        # CSV patch embedding\n",
    "        csv_input = x_csv.permute(0, 2, 1).contiguous()\n",
    "        csv_emb, n_vars_csv = self.csv_patch_embedding(csv_input)\n",
    "\n",
    "        # Video patch embedding\n",
    "        pt_input = x_pt.permute(0, 2, 1).contiguous()\n",
    "        pt_emb, n_vars_pt = self.pt_patch_embedding(pt_input)\n",
    "\n",
    "        # Reprogram CSV and video embeddings\n",
    "        source_embeddings = (\n",
    "            self.mapping_layer(self.word_embeddings.permute(1, 0))\n",
    "            .permute(1, 0))\n",
    "        csv_emb = self.reprogramming_layer(\n",
    "            csv_emb, source_embeddings, source_embeddings)\n",
    "        pt_emb = self.reprogramming_layer(\n",
    "            pt_emb, source_embeddings, source_embeddings)\n",
    "\n",
    "        # Concatenate prompt, video, and CSV embeddings\n",
    "        combined = torch.cat([prompt_embeddings, pt_emb, csv_emb], dim=1)\n",
    "        total_prompt = prompt_embeddings.shape[1]\n",
    "        total_pt = pt_emb.shape[1]\n",
    "        # Pass through frozen LLM\n",
    "        llm_out = self.llm_model(inputs_embeds=combined).last_hidden_state\n",
    "        # Keep only CSV part\n",
    "        csv_out = llm_out[:, total_prompt + total_pt:, :]\n",
    "        csv_out = csv_out[:, :, :self.d_ff]\n",
    "        csv_out = csv_out.view(-1, n_vars_csv, csv_out.size(-2), csv_out.size(-1))\n",
    "        csv_out = csv_out.permute(0, 1, 3, 2).contiguous()\n",
    "        csv_out = self.output_projection(\n",
    "            csv_out[:, :, :, -self.patch_nums:])\n",
    "        csv_out = csv_out.permute(0, 2, 1).contiguous()\n",
    "        csv_out = self.normalize_layers(csv_out, 'denorm')\n",
    "        return csv_out\n",
    "\n",
    "    def calcute_lags(self, x_enc):\n",
    "        q_fft = torch.fft.rfft(\n",
    "            x_enc.permute(0, 2, 1).contiguous(), dim=-1)\n",
    "        k_fft = torch.fft.rfft(\n",
    "            x_enc.permute(0, 2, 1).contiguous(), dim=-1)\n",
    "        res = q_fft * torch.conj(k_fft)\n",
    "        corr = torch.fft.irfft(res, dim=-1)\n",
    "        mean_value = torch.mean(corr, dim=1)\n",
    "        _, lags = torch.topk(mean_value, self.top_k, dim=-1)\n",
    "        return lags\n",
    "\n",
    "\n",
    "#########################################\n",
    "# Utility functions and simple implementations\n",
    "#########################################\n",
    "def del_files(path):\n",
    "    \"\"\"Delete all files in the specified directory.\"\"\"\n",
    "    for file in os.listdir(path):\n",
    "        file_path = os.path.join(path, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, accelerator, patience=10):\n",
    "        self.accelerator = accelerator\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, loss, model, path):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = loss\n",
    "            self.save_checkpoint(model, path)\n",
    "        elif loss > self.best_loss:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = loss\n",
    "            self.save_checkpoint(model, path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, model, path):\n",
    "        torch.save(model.state_dict(), os.path.join(path, 'checkpoint.pt'))\n",
    "\n",
    "def adjust_learning_rate(accelerator, optimizer, scheduler, epoch, args, printout=True):\n",
    "    if printout:\n",
    "        accelerator.print(f\"Current learning rate: {optimizer.param_groups[0]['lr']:.10f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "def vali(args, accelerator, model, data, data_loader, criterion, mae_metric):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_mae = 0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            batch_csv, batch_pt, batch_y, batch_x_mark, batch_y_mark = batch\n",
    "            batch_csv = batch_csv.float().to(accelerator.device)\n",
    "            batch_pt = batch_pt.float().to(accelerator.device)\n",
    "            batch_y = batch_y.float().to(accelerator.device)\n",
    "            batch_x_mark = batch_x_mark.float().to(accelerator.device)\n",
    "            batch_y_mark = batch_y_mark.float().to(accelerator.device)\n",
    "            dec_inp = torch.zeros_like(batch_y[:, -args.pred_len:, :]).float().to(accelerator.device)\n",
    "            dec_inp = torch.cat([batch_y[:, :args.label_len, :], dec_inp], dim=1)\n",
    "            outputs = model(batch_csv, batch_pt, batch_x_mark, dec_inp, batch_y_mark)\n",
    "            outputs = outputs[:, -args.pred_len:, 0:]\n",
    "            batch_y = batch_y[:, -args.pred_len:, 0:]\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            mae = mae_metric(outputs, batch_y)\n",
    "            total_loss += loss.item()\n",
    "            total_mae += mae.item()\n",
    "            count += 1\n",
    "    return total_loss / count, total_mae / count\n",
    "\n",
    "def load_content(args):\n",
    "    \"\"\"Load prompt description content; returns example string.\"\"\"\n",
    "    return \"Example prompt content describing the domain.\"\n",
    "\n",
    "\n",
    "#########################################\n",
    "# Main training loop\n",
    "#########################################\n",
    "if __name__ == '__main__':\n",
    "    os.environ['CURL_CA_BUNDLE'] = ''\n",
    "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\"\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Time-LLM Time Series Forecasting')\n",
    "    fix_seed = 2021\n",
    "    random.seed(fix_seed)\n",
    "    torch.manual_seed(fix_seed)\n",
    "    np.random.seed(fix_seed)\n",
    "\n",
    "    # Required arguments\n",
    "    parser.add_argument('--task_name', type=str, default='long_term_forecast', help='Task name')\n",
    "    parser.add_argument('--is_training', type=int, default=1, help='Training flag, 1 means training')\n",
    "    parser.add_argument('--model_id', type=str, default='ETTh1_512_96', help='Model ID')\n",
    "    parser.add_argument('--model_comment', type=str, default='TimeLLM-ETTh1', help='Model comment')\n",
    "    parser.add_argument('--model', type=str, default='TimeLLM', help='Model name; only TimeLLM supported')\n",
    "\n",
    "    # Data arguments (only ETTh1 dataset supported)\n",
    "    parser.add_argument('--data', type=str, default='PKU_Skeleton_Renew_preprocessed_0002-L.csv', help='Dataset name (only ETTh1)')\n",
    "    parser.add_argument('--root_path', type=str, default='/', help='Root directory for data')\n",
    "    parser.add_argument('--data_path', type=str, default='PKU_Skeleton_Renew_preprocessed_0002-L.csv', help='Data file name')\n",
    "    parser.add_argument('--freq', type=str, default='h', help='Time feature encoding frequency')\n",
    "    parser.add_argument('--checkpoints', type=str, default='./checkpoints/', help='Directory to save checkpoints')\n",
    "    parser.add_argument('--scale', type=bool, default=True, help='Whether to standardize data')\n",
    "\n",
    "    # Forecasting task arguments\n",
    "    parser.add_argument('--seq_len', type=int, default=512, help='Input sequence length')\n",
    "    parser.add_argument('--label_len', type=int, default=48, help='Label length')\n",
    "    parser.add_argument('--pred_len', type=int, default=30, help='Prediction length')\n",
    "    parser.add_argument('--seasonal_patterns', type=str, default='Monthly', help='Seasonal patterns')\n",
    "\n",
    "    # Model architecture arguments\n",
    "    parser.add_argument('--enc_in', type=int, default=75, help='Encoder input size')\n",
    "    parser.add_argument('--dec_in', type=int, default=75, help='Decoder input size')\n",
    "    parser.add_argument('--c_out', type=int, default=75, help='Output size')\n",
    "    parser.add_argument('--d_model', type=int, default=32, help='Model dimension')\n",
    "    parser.add_argument('--n_heads', type=int, default=8, help='Number of attention heads')\n",
    "    parser.add_argument('--e_layers', type=int, default=2, help='Number of encoder layers')\n",
    "    parser.add_argument('--d_layers', type=int, default=1, help='Number of decoder layers')\n",
    "    parser.add_argument('--d_ff', type=int, default=128, help='Feedforward dimension')\n",
    "    parser.add_argument('--moving_avg', type=int, default=25, help='Moving average window size')\n",
    "    parser.add_argument('--factor', type=int, default=3, help='Attention factor')\n",
    "    parser.add_argument('--dropout', type=float, default=0.1, help='Dropout ratio')\n",
    "    parser.add_argument('--embed', type=str, default='timeF', help='Time feature encoding type')\n",
    "    parser.add_argument('--activation', type=str, default='gelu', help='Activation function')\n",
    "    parser.add_argument('--output_attention', action='store_true', help='Whether to output encoder attention')\n",
    "    parser.add_argument('--patch_len', type=int, default=16, help='Patch length')\n",
    "    parser.add_argument('--stride', type=int, default=8, help='Patch stride')\n",
    "    parser.add_argument('--prompt_domain', type=int, default=0, help='Whether to use custom prompt domain')\n",
    "    parser.add_argument('--llm_model', type=str, default='BERT', help='LLM model, fixed to BERT')\n",
    "    parser.add_argument('--llm_dim', type=int, default=768, help='LLM hidden dimension')\n",
    "    parser.add_argument('--llm_layers', type=int, default=12, help='LLM number of layers')\n",
    "\n",
    "    # Optimization arguments\n",
    "    parser.add_argument('--num_workers', type=int, default=10, help='Data loader workers')\n",
    "    parser.add_argument('--itr', type=int, default=1, help='Number of experiments')\n",
    "    parser.add_argument('--train_epochs', type=int, default=20, help='Number of training epochs')\n",
    "    parser.add_argument('--align_epochs', type=int, default=10, help='Number of alignment epochs')\n",
    "    parser.add_argument('--batch_size', type=int, default=24, help='Training batch size')\n",
    "    parser.add_argument('--eval_batch_size', type=int, default=8, help='Evaluation batch size')\n",
    "    parser.add_argument('--patience', type=int, default=10, help='Early stopping patience')\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.01, help='Learning rate')\n",
    "    parser.add_argument('--des', type=str, default='Exp', help='Experiment description')\n",
    "    parser.add_argument('--loss', type=str, default='MSE', help='Loss function')\n",
    "    parser.add_argument('--lradj', type=str, default='type1', help='Learning rate adjustment method')\n",
    "    parser.add_argument('--pct_start', type=float, default=0.2, help='OneCycleLR pct_start')\n",
    "    parser.add_argument('--use_amp', action='store_true', default=False, help='Use mixed precision training')\n",
    "    parser.add_argument('--percent', type=int, default=100, help='Percentage of data usage')\n",
    "\n",
    "    # Use parse_known_args() to ignore extra Colab args (e.g., -f)\n",
    "    args, unknown = parser.parse_known_args()\n",
    "\n",
    "    # Initialize Accelerator without DeepSpeed\n",
    "    ddp_kwargs = DistributedDataParallelKwargs(find_unused_parameters=True)\n",
    "    accelerator = Accelerator(kwargs_handlers=[ddp_kwargs])\n",
    "\n",
    "    # On the local main process, create logs and override accelerator.print\n",
    "    log_f = None\n",
    "    if accelerator.is_local_main_process:\n",
    "        os.makedirs(args.checkpoints, exist_ok=True)\n",
    "        log_file = os.path.join(args.checkpoints, \"training_log.txt\")\n",
    "        log_f = open(log_file, \"w\", encoding=\"utf-8\")\n",
    "        original_print = accelerator.print\n",
    "        def log_print(*args, **kwargs):\n",
    "            msg = \" \".join(str(arg) for arg in args)\n",
    "            original_print(*args, **kwargs)\n",
    "            log_f.write(msg + \"\\n\")\n",
    "            log_f.flush()\n",
    "        accelerator.print = log_print\n",
    "\n",
    "    for ii in range(args.itr):\n",
    "        setting = (\n",
    "            f\"{args.task_name}_{args.model_id}_{args.model}\"\n",
    "            f\"_sl{args.seq_len}_ll{args.label_len}_pl{args.pred_len}\"\n",
    "            f\"_dm{args.d_model}_nh{args.n_heads}_el{args.e_layers}\"\n",
    "            f\"_dl{args.d_layers}_df{args.d_ff}_fc{args.factor}\"\n",
    "            f\"_eb{args.embed}_{args.des}_{ii}\"\n",
    "        )\n",
    "\n",
    "        train_data, train_loader = data_provider(args, 'train')\n",
    "        vali_data, vali_loader = data_provider(args, 'val')\n",
    "        test_data, test_loader = data_provider(args, 'test')\n",
    "\n",
    "        if args.model == 'TimeLLM':\n",
    "            model = Model(args).float()\n",
    "        else:\n",
    "            raise NotImplementedError(\"Only TimeLLM model is supported\")\n",
    "\n",
    "        path = os.path.join(args.checkpoints, setting + '-' + args.model_comment)\n",
    "        args.content = load_content(args)\n",
    "        if not os.path.exists(path) and accelerator.is_local_main_process:\n",
    "            os.makedirs(path)\n",
    "\n",
    "        time_now = time.time()\n",
    "        train_steps = len(train_loader)\n",
    "        early_stopping = EarlyStopping(accelerator=accelerator, patience=args.patience)\n",
    "\n",
    "        trained_parameters = [p for p in model.parameters() if p.requires_grad]\n",
    "        model_optim = optim.Adam(trained_parameters, lr=args.learning_rate)\n",
    "\n",
    "        if args.lradj == 'COS':\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                model_optim, T_max=20, eta_min=1e-8)\n",
    "        else:\n",
    "            scheduler = lr_scheduler.OneCycleLR(\n",
    "                optimizer=model_optim,\n",
    "                steps_per_epoch=train_steps,\n",
    "                pct_start=args.pct_start,\n",
    "                epochs=args.train_epochs,\n",
    "                max_lr=args.learning_rate)\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        mae_metric = nn.L1Loss()\n",
    "\n",
    "        # Prepare with Accelerator (unpack 5 parts: csv, pt, y, x_mark, y_mark)\n",
    "        train_loader, vali_loader, test_loader, model, model_optim, scheduler = accelerator.prepare(\n",
    "            train_loader, vali_loader, test_loader, model, model_optim, scheduler)\n",
    "\n",
    "        if args.use_amp:\n",
    "            scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "        for epoch in range(args.train_epochs):\n",
    "            iter_count = 0\n",
    "            train_loss = []\n",
    "            model.train()\n",
    "            epoch_time = time.time()\n",
    "            for i, (batch_csv, batch_pt, batch_y, batch_x_mark, batch_y_mark) in tqdm(enumerate(train_loader)):\n",
    "                iter_count += 1\n",
    "                model_optim.zero_grad()\n",
    "                batch_csv = batch_csv.float().to(accelerator.device)\n",
    "                batch_pt = batch_pt.float().to(accelerator.device)\n",
    "                batch_y = batch_y.float().to(accelerator.device)\n",
    "                batch_x_mark = batch_x_mark.float().to(accelerator.device)\n",
    "                batch_y_mark = batch_y_mark.float().to(accelerator.device)\n",
    "                dec_inp = torch.zeros_like(batch_y[:, -args.pred_len:, :]).float().to(accelerator.device)\n",
    "                dec_inp = torch.cat([batch_y[:, :args.label_len, :], dec_inp], dim=1)\n",
    "                if args.use_amp:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        outputs = model(\n",
    "                            batch_csv, batch_pt, batch_x_mark,\n",
    "                            dec_inp, batch_y_mark)\n",
    "                        outputs = outputs[:, -args.pred_len:, 0:]\n",
    "                        batch_y = batch_y[:, -args.pred_len:, 0:]\n",
    "                        loss = criterion(outputs, batch_y)\n",
    "                        train_loss.append(loss.item())\n",
    "                else:\n",
    "                    outputs = model(\n",
    "                        batch_csv, batch_pt, batch_x_mark,\n",
    "                        dec_inp, batch_y_mark)\n",
    "                    outputs = outputs[:, -args.pred_len:, 0:]\n",
    "                    batch_y = batch_y[:, -\\\n",
    "args.pred_len:, 0:]\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "                    train_loss.append(loss.item())\n",
    "\n",
    "                if (i + 1) % 100 == 0:\n",
    "                    accelerator.print(\n",
    "                        f\"\\titers: {i+1}, epoch: {epoch+1} | \"\n",
    "                        f\"loss: {loss.item():.7f}\")\n",
    "                    speed = (time.time() - time_now) / iter_count\n",
    "                    left_time = speed * (\n",
    "                        (args.train_epochs - epoch) * train_steps - i)\n",
    "                    accelerator.print(\n",
    "                        f'\\tspeed: {speed:.4f}s/iter; remaining time: {left_time:.4f}s')\n",
    "                    iter_count = 0\n",
    "                    time_now = time.time()\n",
    "\n",
    "                if args.use_amp:\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(model_optim)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    accelerator.backward(loss)\n",
    "                    model_optim.step()\n",
    "\n",
    "                if args.lradj == 'TST':\n",
    "                    adjust_learning_rate(\n",
    "                        accelerator, model_optim, scheduler,\n",
    "                        epoch+1, args, printout=False)\n",
    "                    scheduler.step()\n",
    "\n",
    "            accelerator.print(\n",
    "                f\"Epoch: {epoch+1} time: {time.time()-epoch_time:.2f}s\")\n",
    "            train_loss_avg = np.mean(train_loss)\n",
    "            vali_loss, vali_mae_loss = vali(\n",
    "                args, accelerator, model, vali_data,\n",
    "                vali_loader, criterion, mae_metric)\n",
    "            test_loss, test_mae_loss = vali(\n",
    "                args, accelerator, model, test_data,\n",
    "                test_loader, criterion, mae_metric)\n",
    "            accelerator.print(\n",
    "                f\"Epoch: {epoch+1} | Train Loss: {train_loss_avg:.7f} | \"\n",
    "                f\"Val Loss: {vali_loss:.7f} | Test Loss: {test_loss:.7f} | \"\n",
    "                f\"MAE Loss: {vali_mae_loss:.7f}\")\n",
    "            early_stopping(vali_loss, model, path)\n",
    "            if early_stopping.early_stop:\n",
    "                accelerator.print(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "            if args.lradj != 'TST':\n",
    "                if args.lradj == 'COS':\n",
    "                    scheduler.step()\n",
    "                    accelerator.print(\n",
    "                        f\"Current learning rate: \"\n",
    "                        f\"{model_optim.param_groups[0]['lr']:.10f}\")\n",
    "                else:\n",
    "                    if epoch == 0:\n",
    "                        args.learning_rate = model_optim.param_groups[0]['lr']\n",
    "                        accelerator.print(\n",
    "                            f\"Current learning rate: \"\n",
    "                            f\"{model_optim.param_groups[0]['lr']:.10f}\")\n",
    "                    adjust_learning_rate(\n",
    "                        accelerator, model_optim, scheduler,\n",
    "                        epoch+1, args, printout=True)\n",
    "            else:\n",
    "                accelerator.print(\n",
    "                    f\"Updated learning rate: {scheduler.get_last_lr()[0]}\")\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        accelerator.print(\n",
    "            'Training complete, all files retained.')\n",
    "\n",
    "    if log_f is not None:\n",
    "        log_f.close()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
